ğŸ“° Fake News Detection using BERT + Boosting Models
ğŸš€ Project Overview

This project is a machine learning pipeline for detecting fake news articles. It leverages BERT embeddings for semantic text understanding and trains powerful boosting classifiers like LightGBM, XGBoost, and CatBoost to achieve reliable predictions.

Our best-performing model achieves ~82% accuracy on benchmark datasets, making it suitable for research and real-world applications.

ğŸ“‚ Dataset

We use the Fake News Dataset (Rajat Kumar - Kaggle)
.

Each record contains:

id: Unique article ID

title: Headline of the news

author: Author name

text: News content

label: Target variable â†’ 1 = Fake, 0 = Real

ğŸ“Œ Example row:

id,title,author,text,label
0,Donald Trump Sends Out Embarrassing New Yearâ€™s Eve Message,Daniel Politi,"Donald Trump issued a bizarre, self-congratulatory message on Twitter...",1

ğŸ› ï¸ Tech Stack

Python ğŸ

LightGBM / XGBoost / CatBoost â†’ Gradient boosting models

BERT (Hugging Face Transformers) â†’ Text embeddings

PyTorch â†’ Backend for BERT

Scikit-learn â†’ Model evaluation (Accuracy, F1-score)

NLTK â†’ Preprocessing (stopwords, tokenization)

NumPy & Pandas â†’ Data handling

ğŸ”‘ Key Features

âœ… Preprocessing with NLTK (cleaning, tokenization, stopword removal)
âœ… Context-aware BERT embeddings for feature extraction
âœ… Training with multiple boosting classifiers
âœ… Evaluation with Accuracy and F1-score
âœ… Ready-to-use trained model with joblib serialization

âš™ï¸ Installation

Clone the repository and install dependencies:

git clone https://github.com/your-username/fake-news-detection.git
cd fake-news-detection
pip install -r requirements.txt

Download NLTK resources:

python -m nltk.downloader stopwords punkt

â–¶ï¸ Usage
ğŸ”¹ Training the Model

Place your dataset (news.csv) in the data/ folder and run:

python train.py

This will:

Preprocess the text

Generate BERT embeddings

Train boosting models

Save the trained model to models/fake_news_model.pkl

ğŸ”¹ Testing / Prediction

Use the trained model to classify new articles:

import joblib
from transformers import BertTokenizer, BertModel
import torch
import numpy as np

# Load model

model = joblib.load("models/fake_news_model.pkl")

# Load BERT

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model = BertModel.from_pretrained("bert-base-uncased")

def bert_embeddings(text):
inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
with torch.no_grad():
outputs = bert_model(\*\*inputs)
return outputs.last_hidden_state[:, 0, :].numpy()

# Example news

news = "Quantum Shoes let people FLY instantly, scientists donâ€™t want you to know this!"

X_new = bert_embeddings(news)
prediction = model.predict(X_new)

print("Prediction:", "FAKE" if prediction[0] == 1 else "REAL")

ğŸ“Š Evaluation

We evaluate models with Accuracy and F1-score:

Model Accuracy F1-score
LightGBM 0.82 0.80
XGBoost 0.81 0.79
CatBoost 0.81 0.78
ğŸ“‚ Repository Structure
fake-news-detection/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ news.csv # Dataset
â”œâ”€â”€ models/
â”‚ â””â”€â”€ fake_news_model.pkl # Trained model
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ train.py # Training script
â”‚ â”œâ”€â”€ predict.py # Prediction script
â”‚ â””â”€â”€ utils.py # Helper functions
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ README.md # Documentation
â””â”€â”€ .gitignore # Ignored files

ğŸ¤ Contributing

Contributions are welcome!

Fork the repo

Create a branch (git checkout -b feature-name)

Commit changes (git commit -m "Added new feature")

Push (git push origin feature-name)

Open a Pull Request
